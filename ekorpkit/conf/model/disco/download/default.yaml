# If you're having issues with model downloads, check this to compare SHA's:
check_model_SHA: false #@param{type:"boolean"}
archive_dir: ${..path.archive_dir}
model_dir: ${..path.model_dir}
pretrained_dir: ${..path.pretrained_dir}
models:
  archive_dir: ${..archive_dir}
  model_dir: ${..model_dir}
  pretrained_dir: ${..pretrained_dir}
  model_256:
    SHA: 983e3de6f95c88c81b2ca7ebb2c217933be1973b1ff058776b970f901584613a
    filename: 256x256_diffusion_uncond.pt
    link: https://openaipublic.blob.core.windows.net/diffusion/jul-2021/${.filename}
    link_fb: https://www.dropbox.com/s/9tqnqo930mpnpcn/${.filename}
    archive_path: ${..archive_dir}/models/${.filename}
    path: ${..model_dir}/${.filename}
  model_512:
    SHA: 9c111ab89e214862b76e1fa6a1b3f1d329b1a88281885943d2cdbe357ad57648
    filename: 512x512_diffusion_uncond_finetune_008100.pt
    link: https://the-eye.eu/public/AI/models/512x512_diffusion_unconditional_ImageNet/${.filename}
    link_fb: https://huggingface.co/lowlevelware/512x512_diffusion_unconditional_ImageNet/resolve/main/${.filename}
    archive_path: ${..archive_dir}/models/${.filename}
    path: ${..model_dir}/${.filename}
  model_secondary:
    SHA: 983e3de6f95c88c81b2ca7ebb2c217933be1973b1ff058776b970f901584613a
    filename: secondary_model_imagenet_2.pth
    link: https://huggingface.co/spaces/huggi/secondary_model_imagenet_2.pth/resolve/main/${.filename}
    link_fb: https://the-eye.eu/public/AI/models/v-diffusion/${.filename}
    archive_path: ${..archive_dir}/models/${.filename}
    path: ${..model_dir}/${.filename}
  MiDaS:
    filename: dpt_large-midas-2f21e586.pt
    link: https://github.com/intel-isl/DPT/releases/download/1_0/${.filename}
    archive_path: ${..archive_dir}/models/${.filename}
    path: ${..model_dir}/${.filename}
  model-lpips:
    filename: vgg16-397923af.pth
    link: https://download.pytorch.org/models/${.filename}
    archive_path: ${..archive_dir}/model-lpips/${.filename}
    path: ${dir.home}/.cache/torch/hub/checkpoints/${.filename}
  AdaBins:
    filename: AdaBins_nyu.pt
    link: https://cloudflare-ipfs.com/ipfs/Qmd2mMnDLWePKmgfS8m6ntAg4nhV5VkUyAydYBp8cWWeB7/AdaBins_nyu.pt
    archive_path: ${..archive_dir}/pretrained/${.filename}
    path: ${..pretrained_dir}/${.filename}
  RN50:
    filename: RN50.pt
    link: https://openaipublic.azureedge.net/clip/models/afeb0e10f9e5a86da6080e35cf09123aca3b358a0c3e3b6c78a7b63bc04b6762/RN50.pt
    archive_path: ${..archive_dir}/clip/${.filename}
    path: ${dir.home}/.cache/clip/${.filename}
  RN101:
    filename: RN101.pt
    link: https://openaipublic.azureedge.net/clip/models/8fa8567bab74a42d41c5915025a8e4538c3bdbe8804a470a72f30b0d94fab599/RN101.pt
    archive_path: ${..archive_dir}/clip/${.filename}
    path: ${dir.home}/.cache/clip/${.filename}
  RN50x4:
    filename: RN50x4.pt
    link: https://openaipublic.azureedge.net/clip/models/7e526bd135e493cef0776de27d5f42653e6b4c8bf9e0f653bb11773263205fdd/RN50x4.pt
    archive_path: ${..archive_dir}/clip/${.filename}
    path: ${dir.home}/.cache/clip/${.filename}
  RN50x16:
    filename: RN50x16.pt
    link: https://openaipublic.azureedge.net/clip/models/52378b407f34354e150460fe41077663dd5b39c54cd0bfd2b27167a4a06ec9aa/RN50x16.pt
    archive_path: ${..archive_dir}/clip/${.filename}
    path: ${dir.home}/.cache/clip/${.filename}
  RN50x64:
    filename: RN50x64.pt
    link: https://openaipublic.azureedge.net/clip/models/be1cfb55d75a9666199fb2206c106743da0f6468c9d327f3e0d0a543a9919d9c/RN50x64.pt
    archive_path: ${..archive_dir}/clip/${.filename}
    path: ${dir.home}/.cache/clip/${.filename}
  ViT-B-32:
    filename: ViT-B-32.pt
    link: https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt
    archive_path: ${..archive_dir}/clip/${.filename}
    path: ${dir.home}/.cache/clip/${.filename}
  ViT-B-16:
    filename: ViT-B-16.pt
    link: https://openaipublic.azureedge.net/clip/models/5806e77cd80f8b59890b7e101eabd078d9fb84e6937f9e85e4ecb61988df416f/ViT-B-16.pt
    archive_path: ${..archive_dir}/clip/${.filename}
    path: ${dir.home}/.cache/clip/${.filename}
  ViT-L-14:
    filename: ViT-L-14.pt
    link: https://openaipublic.azureedge.net/clip/models/b8cca3fd41ae0c99ba7e8951adf17d267cdb84cd88be6f7c2e0eca1737a03836/ViT-L-14.pt
    archive_path: ${..archive_dir}/clip/${.filename}
    path: ${dir.home}/.cache/clip/${.filename}
